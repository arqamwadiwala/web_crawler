# web_crawler
I have created a multi-threaded web crawler to search and index web pages more efficiently and quickly a queue however will be maintained for proper processing and scheduling as well through a scheduler 
